{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://www.cognitiveclass.ai\"><img src = \"https://cognitiveclass.ai/wp-content/themes/bdu3.0/static/images/cc-logo.png\" align = left></a>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "--------------------\n",
    "# Signal to Binary Files (Train&Test)\n",
    "\n",
    "In this notebook we read the Basic 4 dataset through Spark, and convert signals into a binary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "#!pip install ibmseti\n",
    "import ibmseti\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "#!pip install pandas\n",
    "#import pandas as pd   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import random\n",
    "sc = pyspark.SparkContext(appName=\"seti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### SET YOUR TEAM NAME HERE! Use this folder to save intermediate results\n",
    "team_name = 'Saeed_team'\n",
    "mydatafolder = os.path.join( os.environ['PWD'], team_name )  #Change my_data_folder to your team name\n",
    "if os.path.exists(mydatafolder) is False:\n",
    "    os.makedirs(mydatafolder)\n",
    "    \n",
    "## REMEMBER, on Nimbix, your local file space is destroyed when your cloud machine is shut down. So be sure to commit/save your work!\n",
    "\n",
    "basicIndex = '/data/seti/simsignals_files/public_list_basic_v2_26may_2017.csv' \n",
    "basicSetiDataDir = '/data/seti/simsignals_basic_v2'\n",
    "\n",
    "workingDataDir = basicSetiDataDir\n",
    "mydatafolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Get file list\n",
    "\n",
    "I have a list of simulated files stored in an OpenStack Object Storage container that is world-readable.\n",
    "\n",
    "Download that file, split by lines and parallelize it into an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_filename_lb(row):  \n",
    "    try:\n",
    "        uuid, class_lb = row.split(',')\n",
    "    except:\n",
    "        uuid = row #this handles the test data since it doesn't have \"SIGNAL_CLASSIFICATION\" in index file\n",
    "        class_lb = 'unknown'\n",
    "    return [class_lb,uuid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# we parallelize the index file across our worker executors\n",
    "filename_rdd = sc.textFile(basicIndex).filter(lambda x: x.startswith('UUID') is False).map(lambda row: get_filename_lb(row)) #the filter removes the header\n",
    "filename_rdd.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Get the class label dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rdd_fname_lb = filename_rdd.map(lambda row: (row[0],row[1]))\n",
    "classes = rdd_fname_lb.map(lambda row: row[0]).distinct().collect()\n",
    "dictClass = dict(zip(classes, np.arange(4)))\n",
    "dictClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Open data, and convert signals to spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_spectrogram(uuid,h,w,lengthRatio=1.0):\n",
    "    \n",
    "    #create path to local data file\n",
    "    filename = uuid + '.dat'\n",
    "    filepath = os.path.join(workingDataDir, filename)\n",
    "    \n",
    "    #retrieve that data file\n",
    "    rawdata = open(filepath).read()\n",
    "    \n",
    "    \n",
    "    aca = ibmseti.compamp.SimCompamp(rawdata)\n",
    "    com_data = aca.complex_data()\n",
    "    ratio = int(np.sqrt(len(com_data) *lengthRatio / (h*w)))\n",
    "    if ratio == 0: \n",
    "        raise ValueError, \"The selected lenght of signal is less than (Height x Width), select bigger ratio\"\n",
    "    elif ratio == 1:\n",
    "        sig_data = com_data[:h*w].reshape(h,w)\n",
    "        spec = np.abs( np.fft.fftshift( np.fft.fft(sig_data), 1) )**2\n",
    "        spec = np.log(spec) # Convert to float (0-255)\n",
    "        image = 255*(spec/np.max(spec)) \n",
    "    elif ratio > 1: # resize using IPL image\n",
    "        sig_data = com_data[:h*ratio*w*ratio].reshape(h*ratio,w*ratio)\n",
    "        spec = np.abs( np.fft.fftshift( np.fft.fft(sig_data), 1) )**2\n",
    "        spec = np.log(spec) # Convert to float (0-255)\n",
    "        image = 255*(spec/np.max(spec)) \n",
    "        img = Image.fromarray(image)  \n",
    "        img = img.resize((int(w), int(h)), Image.ANTIALIAS)\n",
    "        image = np.asarray(img) # float (0-255)\n",
    "        \n",
    "                \n",
    "        # convert to grayscale: int(0-255)\n",
    "        image = np.uint8(image)\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "h and w are the hight and width of the images, and lengthRatio is the length of signal in ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "h = 64 # The hight of output image (bins)\n",
    "w = 128 # The witdh of output image\n",
    "lengthRatio = 1.0  # the length-ration of signal to be read. The higher reatio, the better resolution. E.g. 0.5 means half of time sereis.\n",
    "rdd_gray_spec = filename_rdd.map(lambda row: (row[1], dictClass[row[0]],  get_spectrogram(row[1],h,w,lengthRatio)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "rdd_gray_spec.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "z=5\n",
    "y= rdd_gray_spec.take(z)\n",
    "for i in range(z):\n",
    "    img = Image.fromarray(np.float32(y[i][2]))\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "test, train = rdd_gray_spec.randomSplit(weights=[0.3, 0.7], seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "train_data = train.map(lambda row: row[2]).collect()\n",
    "train_img_data = np.array(train_data)\n",
    "train_lbl = train.map(lambda row: row[1]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "test_data = test.map(lambda row: row[2]).collect()\n",
    "test_img_data = np.array(test_data)\n",
    "test_lbl = test.map(lambda row: row[1]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Write to Binary file\n",
    "This binary file is same as famouse __mnist__ dataset format to be read by different image processing algorithms, learning techniques and pattern recognition methods. \n",
    "\n",
    "There are 4 files:  \n",
    "\n",
    "- train-images-idx3-ubyte: training set images \n",
    "- train-labels-idx1-ubyte: training set labels \n",
    "- test-images-idx3-ubyte:  test set images \n",
    "- test-labels-idx1-ubyte:  test set labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from array import *\n",
    "def wrtieToBinary(ds_directory, name , imgData , lblData,h,w):\n",
    "    \n",
    "    n = imgData.shape[0]\n",
    "    imgData = imgData.reshape(-1,)\n",
    "    \n",
    "    data_image = array('B')\n",
    "    data_label = array('B')\n",
    "    \n",
    "    data_image.extend(imgData)\n",
    "\n",
    "    # number of files in HEX\n",
    "    hexval = \"{0:#0{1}x}\".format(n,6) \n",
    "    \n",
    "    # header for label array\n",
    "    data_label.extend(lblData)\n",
    "    header = array('B')\n",
    "    header.extend([0,0,8,1,0,0])\n",
    "    header.append(int('0x'+hexval[2:][:2],16))\n",
    "    header.append(int('0x'+hexval[2:][2:],16))\n",
    "    data_label = header + data_label\n",
    "    print ('Label header:' )\n",
    "    print(header)\n",
    "    # additional header for images array\n",
    "    if max([w,h]) <= 255:\n",
    "        header.extend([0,0,0,h,0,0,0,w])\n",
    "    else:\n",
    "        hex_h = \"{0:#0{1}x}\".format(h,6)\n",
    "        header.extend([0,0])\n",
    "        header.append(int('0x'+hex_h[2:][:2],16))\n",
    "        header.append(int('0x'+hex_h[2:][2:],16))\n",
    "        hex_w = \"{0:#0{1}x}\".format(w,6)\n",
    "        header.extend([0,0])\n",
    "        header.append(int('0x'+hex_w[2:][:2],16))\n",
    "        header.append(int('0x'+hex_w[2:][2:],16))\n",
    "        #raise ValueError('Image exceeds maximum size: 256x256 pixels');\n",
    "    header[3] = 3 # Changing MSB for image data (0x00000803)\n",
    "        \n",
    "    if not os.path.exists(ds_directory):\n",
    "        os.makedirs(ds_directory)\n",
    "            \n",
    "        \n",
    "    print ('Image header:' )\n",
    "    print(header)\n",
    "    data_image = header + data_image\n",
    "\n",
    "    output_file = open(ds_directory + name+'-images-idx3-ubyte', 'wb')\n",
    "    data_image.tofile(output_file)\n",
    "    output_file.close()\n",
    "\n",
    "    output_file = open(ds_directory+ name+'-labels-idx1-ubyte', 'wb')\n",
    "    data_label.tofile(output_file)\n",
    "    output_file.close()\n",
    "    \n",
    "    # gzip resulting files\n",
    "\n",
    "\n",
    "    os.system('gzip '+ ds_directory + name +'-images-idx3-ubyte '+ name +'-images-idx3-ubyte.gz')\n",
    "    os.system('gzip '+ ds_directory + name +'-labels-idx1-ubyte ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ds_directory = mydatafolder + '/SETI/SETI_ds_64x128/'  # The dataset directory to write the binary files\n",
    "os.system('rm '+ds_directory+'*')\n",
    "print os.popen(\"ls -lrt \"+ ds_directory).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wrtieToBinary(ds_directory, 'train' , train_img_data , train_lbl, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "wrtieToBinary(ds_directory, 'test' , test_img_data , test_lbl, h, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Verify the binary files\n",
    "Lets read the binary file and plot an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print os.popen(\"ls -lrt \"+ ds_directory).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "def _read32(bytestream):\n",
    "  dt = np.dtype(np.uint32).newbyteorder('>')\n",
    "  return np.frombuffer(bytestream.read(4), dtype=dt)[0]\n",
    "\n",
    "with open(ds_directory+'train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    with gzip.GzipFile(fileobj=f ) as bytestream:\n",
    "        magic = _read32(bytestream)\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Invalid magic number %d in MNIST image file: %s' %(magic, f.name))\n",
    "        num_images = _read32(bytestream)\n",
    "        rows = _read32(bytestream)\n",
    "        cols = _read32(bytestream)\n",
    "        buf = bytestream.read(rows * cols * num_images)\n",
    "        print(magic,num_images,rows,cols,)\n",
    "        \n",
    "        data = np.frombuffer(buf, dtype=np.uint8)\n",
    "        data = data.reshape(num_images, rows, cols, 1)\n",
    "# magic, num, rows, cols = struct.unpack(\">IIII\", bytestream.read(16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "gray_y = data[0].reshape(h,w)\n",
    "img = Image.fromarray(np.float32(gray_y))\n",
    "print (img.mode)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "gray_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Verify the binary files by reader class\n",
    "__SETI.py__ is a helper class, identical to mnist dataset reader, to easily read dataset, one-hot coding, and read images as batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "!wget -q --output-document SETI.zip  https://ibm.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip\n",
    "!unzip -o SETI.zip\n",
    "import SETI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "SETIds = SETI.read_data_sets(ds_directory, one_hot=True, validation_size=0)\n",
    "SETIds.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "gray_y = SETIds.train.images[0].reshape(h,w)\n",
    "img = Image.fromarray(gray_y*255)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!ls /home/nimbix/Saeed_team/SETI/SETI_ds_64x128/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# old    \n",
    "#  \n",
    "# primarySmallIndex = '/data/seti/simsignals_files/public_list_primary_v2_small_1june_2017.csv' \n",
    "# primaryMediumIndex = '/data/seti/simsignals_files/public_list_primary_v2_medium_1june_2017.csv'\n",
    "#testSetIndex =  '/data/seti/simsignals_files/public_list_primary_testset_mini_1june_2017.csv'\n",
    "#primarySetiDataDir = '/data/seti/simsignals_v2'  #THIS ONLY CONTAINS THE SMALL AND MEDIUM DATA FILES!  \n",
    "# Ask Adam, Patrick or Joseph on Saturday evening if you want the full data set. Hint: It's in simsignals_v2_full_N, for N=1,2,3,4 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors\n",
    "\n",
    "<div class=\"teacher-image\" style=\"    float: left;\n",
    "    width: 115px;\n",
    "    height: 115px;\n",
    "    margin-right: 10px;\n",
    "    margin-bottom: 10px;\n",
    "    border: 1px solid #CCC;\n",
    "    padding: 3px;\n",
    "    border-radius: 3px;\n",
    "    text-align: center;\"><img class=\"alignnone wp-image-2258 \" src=\"https://ibm.box.com/shared/static/tyd41rlrnmfrrk78jx521eb73fljwvv0.jpg\" alt=\"Saeed Aghabozorgi\" width=\"178\" height=\"178\" /></div>\n",
    "#### Saeed Aghabozorgi\n",
    "\n",
    "[Saeed Aghabozorgi](https://ca.linkedin.com/in/saeedaghabozorgi), PhD is Sr. Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clientsâ€™ ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
